{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "intro_cell"
   },
   "source": [
    "# Week 14: CNN Lab - Rock, Paper, Scissors\n",
    "\n",
    "**Objective:** Build, train, and test a Convolutional Neural Network (CNN) to classify images of hands playing Rock, Paper, or Scissors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step_1_md"
   },
   "source": [
    "### Step 1: Setup and Data Download\n",
    "\n",
    "This first cell downloads the dataset from Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "DHpeGiatx8yO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already extracted manually. Skipping KaggleHub download.\n"
     ]
    }
   ],
   "source": [
    "# KaggleHub not needed because dataset was downloaded manually\n",
    "print(\"Dataset already extracted manually. Skipping KaggleHub download.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "3SVJhchl2XCb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied: rock\n",
      "Copied: paper\n",
      "Copied: scissors\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "# Path to your manually extracted dataset\n",
    "src_root = \"archive\"          # your local folder containing rock/paper/scissors\n",
    "dst_root = \"dataset\"          # folder you want to use for training\n",
    "\n",
    "os.makedirs(dst_root, exist_ok=True)\n",
    "\n",
    "folders_to_copy = [\"rock\", \"paper\", \"scissors\"]\n",
    "\n",
    "for folder in folders_to_copy:\n",
    "    src_path = os.path.join(src_root, folder)\n",
    "    dst_path = os.path.join(dst_root, folder)\n",
    "\n",
    "    if os.path.exists(src_path):\n",
    "        shutil.copytree(src_path, dst_path, dirs_exist_ok=True)\n",
    "        print(\"Copied:\", folder)\n",
    "    else:\n",
    "        print(\"Folder not found:\", folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step_2_md"
   },
   "source": [
    "### Step 2: Imports and Device Setup\n",
    "\n",
    "Import the necessary libraries and check if a GPU is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "1n2gYN8TyydM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# TODO: Set the 'device' variable\n",
    "# Check if CUDA (GPU) is available, otherwise use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step_3_md"
   },
   "source": [
    "### Step 3: Data Loading and Preprocessing\n",
    "\n",
    "Here we will define our image transformations, load the dataset, split it, and create DataLoaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "SkJ5XlSDy0HF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['paper', 'rock', 'scissors']\n",
      "Total images: 2188\n",
      "Training images: 1750\n",
      "Test images: 438\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = \"dataset\"\n",
    "\n",
    "# TODO: Define the image transforms\n",
    "# 1. Resize to 128x128\n",
    "# 2. Convert to Tensor\n",
    "# 3. Normalize with mean=0.5, std=0.5\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "# Load dataset using ImageFolder\n",
    "full_dataset = datasets.ImageFolder(DATA_DIR, transform=transform)\n",
    "\n",
    "class_names = full_dataset.classes\n",
    "print(\"Classes:\", class_names)\n",
    "\n",
    "# TODO: Split the dataset (80% train, 20% test)\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size\n",
    "\n",
    "# TODO: Create splits\n",
    "train_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])\n",
    "\n",
    "# TODO: Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(f\"Total images: {len(full_dataset)}\")\n",
    "print(f\"Training images: {len(train_dataset)}\")\n",
    "print(f\"Test images: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step_4_md"
   },
   "source": [
    "### Step 4: Define the CNN Model\n",
    "\n",
    "Fill in the `conv_block` and `fc_block` with the correct layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wexPK8V3y3Fx"
   },
   "outputs": [],
   "source": [
    "class RPS_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RPS_CNN, self).__init__()\n",
    "\n",
    "        # TODO: Define the convolutional block\n",
    "        # We want 3 blocks:\n",
    "        # 1. Conv2d(3 -> 16 channels, kernel=3, padding=1), ReLU, MaxPool2d(2)\n",
    "        # 2. Conv2d(16 -> 32 channels, kernel=3, padding=1), ReLU, MaxPool2d(2)\n",
    "        # 3. Conv2d(32 -> 64 channels, kernel=3, padding=1), ReLU, MaxPool2d(2)\n",
    "        self.conv_block = nn.Sequential(\n",
    "            # ... Your layers here\n",
    "        )\n",
    "\n",
    "        # After 3 MaxPool(2) layers, our 128x128 image becomes:\n",
    "        # 128 -> 64 -> 32 -> 16\n",
    "        # So the flattened size is 64 * 16 * 16\n",
    "\n",
    "        # TODO: Define the fully-connected (classifier) block\n",
    "        # We want:\n",
    "        # 1. Flatten the input\n",
    "        # 2. Linear layer (64 * 16 * 16 -> 256)\n",
    "        # 3. ReLU\n",
    "        # 4. Dropout (p=0.3)\n",
    "        # 5. Linear layer (256 -> 3) (3 classes: rock, paper, scissors)\n",
    "        self.fc = nn.Sequential(\n",
    "            # ... Your layers here\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_block(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# TODO: Initialize the model, criterion, and optimizer\n",
    "# 1. Create an instance of RPS_CNN and move it to the 'device'\n",
    "model = None # <-- Replace this\n",
    "\n",
    "# 2. Define the loss function (Criterion). Use CrossEntropyLoss for classification.\n",
    "criterion = None # <-- Replace this\n",
    "\n",
    "# 3. Define the optimizer. Use Adam with a learning rate of 0.001\n",
    "optimizer = None # <-- Replace this\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step_5_md"
   },
   "source": [
    "### Step 5: Train the Model\n",
    "\n",
    "Fill in the core training steps inside the loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "L_GqO57IzQLs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RPS_CNN(\n",
      "  (conv_block): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=16384, out_features=256, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.3, inplace=False)\n",
      "    (4): Linear(in_features=256, out_features=3, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class RPS_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RPS_CNN, self).__init__()\n",
    "\n",
    "        # TODO: Convolutional block (3 blocks)\n",
    "        self.conv_block = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        # After 3 maxpools: 128 → 64 → 32 → 16\n",
    "        # Flatten size = 64 * 16 * 16\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 16 * 16, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 3)  # 3 classes\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_block(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# TODO: Initialize the model, criterion, optimizer\n",
    "\n",
    "# 1. Model\n",
    "model = RPS_CNN().to(device)\n",
    "\n",
    "# 2. Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 3. Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step_6_md"
   },
   "source": [
    "### Step 6: Evaluate the Model\n",
    "\n",
    "Test the model's accuracy on the unseen test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "iYCNxBrjzU1t"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 34.02%\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# TODO: Use torch.no_grad()\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # 1. Get model outputs\n",
    "        outputs = model(images)\n",
    "\n",
    "        # 2. Get predicted class\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step_7_md"
   },
   "source": [
    "### Step 7: Test on a Single Image\n",
    "\n",
    "Let's see how the model performs on one image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "RN00Dkw9zceh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model prediction for dataset/paper/0Uomd0HvOB33m47I.png: paper\n"
     ]
    }
   ],
   "source": [
    "def predict_image(model, img_path):\n",
    "    model.eval()\n",
    "\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    img = transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # 1. Get model outputs\n",
    "        output = model(img)\n",
    "\n",
    "        # 2. Predicted class index\n",
    "        _, pred = torch.max(output, 1)\n",
    "\n",
    "    return class_names[pred.item()]\n",
    "\n",
    "# Test the function (make sure this path exists in your dataset)\n",
    "test_img_path = \"dataset/paper/0Uomd0HvOB33m47I.png\"\n",
    "prediction = predict_image(model, test_img_path)\n",
    "print(f\"Model prediction for {test_img_path}: {prediction}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step_8_md"
   },
   "source": [
    "### Step 8: Play the Game!\n",
    "\n",
    "This code is complete. If your model is trained, you can run this cell to have the model play against itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "13-RXEbuzuxu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly selected images:\n",
      "Image 1: dataset/rock\\2Pt5UNQkMzXLtbEp.png\n",
      "Image 2: dataset/paper\\Arbkrts1pXpDNgFV.png\n",
      "\n",
      "Player 1 shows: paper\n",
      "Player 2 shows: paper\n",
      "\n",
      "RESULT: Draw\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "\n",
    "def pick_random_image(class_name):\n",
    "    folder = f\"dataset/{class_name}\"\n",
    "    files = os.listdir(folder)\n",
    "    img = random.choice(files)\n",
    "    return os.path.join(folder, img)\n",
    "\n",
    "def rps_winner(move1, move2):\n",
    "    if move1 == move2:\n",
    "        return \"Draw\"\n",
    "\n",
    "    rules = {\n",
    "        \"rock\": \"scissors\",\n",
    "        \"paper\": \"rock\",\n",
    "        \"scissors\": \"paper\"\n",
    "    }\n",
    "\n",
    "    if rules[move1] == move2:\n",
    "        return f\"Player 1 wins! {move1} beats {move2}\"\n",
    "    else:\n",
    "        return f\"Player 2 wins! {move2} beats {move1}\"\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 1. Choose any two random classes\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "choices = [\"rock\", \"paper\", \"scissors\"]\n",
    "c1 = random.choice(choices)\n",
    "c2 = random.choice(choices)\n",
    "\n",
    "img1_path = pick_random_image(c1)\n",
    "img2_path = pick_random_image(c2)\n",
    "\n",
    "print(\"Randomly selected images:\")\n",
    "print(\"Image 1:\", img1_path)\n",
    "print(\"Image 2:\", img2_path)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 2. Predict their labels using the model\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "p1 = predict_image(model, img1_path)\n",
    "p2 = predict_image(model, img2_path)\n",
    "\n",
    "print(\"\\nPlayer 1 shows:\", p1)\n",
    "print(\"Player 2 shows:\", p2)\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 3. Decide the winner\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "print(\"\\nRESULT:\", rps_winner(p1, p2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
